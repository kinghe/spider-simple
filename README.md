#spider-simple

简易的网络爬虫系统

##系统设计思路(System Design)
爬虫系统应该包括如下部分
###1任务管理模块task module。

用户和系统交互的中转部分,主要包括UI用户交互模块和任务执行模块。
任务主要包括4个状态`status`。
* `TODO` 由用户新建时预定义，主要用于任务后的状态识别。任务可以立即执行或者定时执行。
* `DOING` 任务开始启动时由任务模块变更任务状态。
* `DONE` 任务完成状态标志。由任务模块在所有任务结束后，负责变更到此任务状态，同时更新任务统计信息`statistics`。
* `UNDO` 任务取消，由用户手工确认后系统变更此标示，注意：
	* 1.任务处于UNDO/DONE时不可变更到此标示,即不可对以及取消或者以及完成的任务进行取消，操作无意义。
	* 2.任务处于`TODO`状态时，直接变更状态即可，无需通知任务执行模块。
	* 3.任务处于`DOING`状态时，不可直接变更状态需通知任务执行系统停止此任务的所有执行后，由任务执行系统变更到此状态，并同时统计任务已执行情况。

`template`任务规则或者模板.任务的核心部分，为任务执行模块的主要参考信息。
任务执行模块需对以及完成下载资源进行数据分析。并根据以下信息完成相关工作。
* 资源分组匹配。根据资源文件类型划分大的资源分组，并建立相关分组索引。默认资源分组包括:`网页HTML`,`多媒体multi-media`,`其他other`.
* 爬取资源过滤匹配。为资源爬取策略部分。即发现下一深度待爬取资源并提交资源下载模块。资源分组部分设计详见数据分析模块。
* 数据分组匹配。从`HTML`中获取匹配数据。并建立关键字分组，用于
	* 搜索索引。将资源分组，从各个组资源中发现若干有用词`valid word`，用于和本组资源的映射工作。详见现代搜索引擎SEO。
	* 数据整合索引。对用户关系的话题建立list/map/tree方便浏览
具体详见数据分析模块设计。
* 通知系统。任务状态变化或者指定分组的资源状态变化后，通知用户。通知包括email，sms，app等。详见通知通知模块的详细设计。


为适应多种用户，提供多种场景操作模式`scene`。
* `最简操作模式`。界面设计要求便捷，易操作。用户仅需提供一个url人口即可，资源爬取策略和数据分析挖掘模块由开发人员按照用户要求设计开发定制，以默认模板的方式提供。
* `定制操作模式`。提供自定义模板管理功能。对用户要求较高，用于更加精细化的任务定制,包括资源爬取策略和数据分析挖掘策略的自定义。

数据模型定义
* `task` :爬虫任务/spider task。
	* |--id:pk
	* |--`status`:任务状态.新建待运行TODO，运行中DOING，完成DONE，任务取消UNDO.
	* |--url:资源入口。用于获取的第一个资源
	* |--depth:资源爬取深度.
	* |--start:任务启动时间(用于定时启动).
	* |--`template`:任务使用的爬虫规则模板(资源爬虫策略，数据分析挖掘，通知系统email或者sms等)
	* |--description:任务描述
	* |--`statistics`:执行结果(成功success，部分成功?half-success，失败failture)，爬取资源统计(总数,成功，失败)，耗时统计(总耗时，成功资源平均下载速度，失败资源耗时)，最优/差下载速度资源列举

###2.资源下载模块down module。
主要包括远程下载模块，本地资源存储
默认http方式下载，method为`get`,url中包括所有的请求内容.
请求附加可以改变请求类型，增加cookie。
下载完成后，分析资源类型，主要是
包括但不限于`html,js,css,jpg/png/gif,mp3/flv/mp4`.<br>
默认保存到本地存储系统，本地存储路径定义在config文件中<br>
每次下载均下载情况存储至sqlite数据表`down`中<br>

* `down`:资源下载信息/down info。
	* |--id:pk
	* |--url:资源路径
	* |--taskid:任务号，
	* |--depth:爬虫深度，
	* |--parent:来源资源，
	* |--robot:执行爬虫(用于分布式系统)，
	* |--status:资源状态(新建/下载中/成功/失败)
	* |--tag:资源标签，用于索引查询
	* |--start:开始时间，
	* |--cost:下载所需时间(ms)
	* |--size:资源大小。(Byte)
	* |--charset:资源字符集。
	* |--`index`:资源索引。

###3.数据分析模块/data parse module。
资源下载完成后随即进行数据分析过程。

* 根据规则文件定义，启动对指定资源类型的数据分析工作。并将数据分析结果反馈至`data-parse`表中。
	* `HTML文档`。爬虫系统的核心部分之一，系统将根据`HTML文档`解析为`DOM树`,使用`CSS`的方式分析指定的元素，挖掘出
		* 新待下载资源。新建下一深度的资源列表，并保持至`down-res`表。`description@data-parse`记录资源id列表，个数。
		* 数据汇总/统计。为数据挖掘部分，挑选出用户需要的信息并输出至指定文档中。
	* `XML文档`。如`RSS`，`WebService`等服务。
	* `图片文档`。图片的基本信息，如类型，大小，长宽等。后续深入图形学研究后进一步挖掘有用信息。

* `data-parse`:记录每个资源(url)分析信息
	* |--url:pk
	* |--path:本地文件相对路径，
	* |--task-id:任务号，
	* |--down-id:对应的下载资源号，
	* |--last:最近更新日期，
	* |--type:资源类型(html,其他)，
	* |--description:资源描述。

###4.策略模块/strategy module。
根据资源类型，名称选择相关的数据解析模块。若无法找到资源解析器，不予解析.其中，HTML解析为核心模块。规则管理模块主要也是针对的html的解析。<br>

* 规则定义(syntax)。
	* 基础语法结构B:`选择器selectors`{`标签处理tag handle`}。采用css语法获取待分析元素。
		* 选择器selector.采用CSS2语法。
		* 标签处理tag handle。与css2相异。CSS2是对符合选择器的所有元素属性值的统一设置，而本规则是对符合选择器的所有元素属性值的迭代处理。
			* down url.新下载资源`url`。
			* select data into gbl_list。将数据append指定的全局资源列表`gbl_list`中。其中`gbl_list`为数组，data为字符串string，数组list，或者字典map。当data为list|map时,常用于单个资源，或整个task完成后的统计分析工作
			* group gbl_list [by index/key].为`gbl_list`分组
			* template template_name.引用规则模板完成数据处理。
	* 复合语法结构C。`选择器selectors`[(B|C)+]
* 规则模板(template)。对常用的规则完成模板化。

###后续模块扩展的考虑

* 系统认证模块(cookies)
* 定时采集
* 定时通知
